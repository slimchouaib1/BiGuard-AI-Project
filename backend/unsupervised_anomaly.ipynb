{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ad75cf",
   "metadata": {},
   "source": [
    "# Unsupervised Fraud Detection (BiGuard)\n",
    "Time-based train/test split without using labels for training. Labels are only revealed for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff9e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "EXCEL_PATH = 'fraud_unsupervised.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31692cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load sheets\n",
    "tx = pd.read_excel(EXCEL_PATH, sheet_name='transactions')\n",
    "labels = pd.read_excel(EXCEL_PATH, sheet_name='labels')  # id -> is_fraudulent\n",
    "\n",
    "# Basic cleaning\n",
    "tx['date'] = pd.to_datetime(tx['date'], errors='coerce')\n",
    "assert tx['date'].isna().sum() == 0, 'There are missing/invalid dates.'\n",
    "\n",
    "tx['amount'] = pd.to_numeric(tx['amount'], errors='coerce').abs()\n",
    "tx['category'] = tx['category'].fillna('Unknown')\n",
    "tx['merchant_name'] = tx['merchant_name'].fillna('')\n",
    "tx['name'] = tx['name'].fillna('')\n",
    "tx['is_expense'] = tx['is_expense'].fillna(1).astype(int)\n",
    "\n",
    "print('Rows:', len(tx))\n",
    "print('Time range:', tx['date'].min().date(), '->', tx['date'].max().date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd87cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature engineering (no labels used)\n",
    "def featurize(df):\n",
    "    out = pd.DataFrame()\n",
    "    out['amount'] = df['amount'].values\n",
    "    out['amount_log'] = np.log(df['amount'].values + 1.0)\n",
    "    out['amount_sqrt'] = np.sqrt(df['amount'].values)\n",
    "    out['is_expense'] = df['is_expense'].astype(int).values\n",
    "    out['day_of_week'] = df['date'].dt.weekday.values\n",
    "    out['day_of_month'] = df['date'].dt.day.values\n",
    "    out['month'] = df['date'].dt.month.values\n",
    "    out['merchant_length'] = df['merchant_name'].astype(str).str.len().values\n",
    "    out['has_numbers'] = df['merchant_name'].astype(str).str.contains(r'\\d').astype(int).values\n",
    "    out['category_hash'] = df['category'].astype(str).apply(lambda s: hash(s)%1000).values\n",
    "    return out\n",
    "\n",
    "X_all = featurize(tx)\n",
    "X_all.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e24295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Time-based split (train on earlier dates, test on later dates)\n",
    "cutoff = tx['date'].quantile(0.8)  # 80% earliest for train\n",
    "train_mask = tx['date'] <= cutoff\n",
    "test_mask = tx['date'] > cutoff\n",
    "\n",
    "X_train, X_test = X_all[train_mask].reset_index(drop=True), X_all[test_mask].reset_index(drop=True)\n",
    "tx_train, tx_test = tx[train_mask].reset_index(drop=True), tx[test_mask].reset_index(drop=True)\n",
    "\n",
    "print('Train rows:', len(X_train), '| Test rows:', len(X_test))\n",
    "print('Cutoff date:', cutoff.date())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e9b298",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scale\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "Xs_train = scaler.transform(X_train)\n",
    "Xs_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392f124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train IsolationForest (unsupervised)\n",
    "iso = IsolationForest(n_estimators=256, contamination=0.09, random_state=42)\n",
    "iso.fit(Xs_train)\n",
    "\n",
    "# Optional DBSCAN for combined signal\n",
    "dbscan_train = DBSCAN(eps=0.7, min_samples=8).fit(Xs_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133579d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict anomalies on TEST ONLY\n",
    "iso_pred = (iso.predict(Xs_test) == -1).astype(int)  # 1 = anomaly\n",
    "iso_score = iso.decision_function(Xs_test)           # higher = more normal\n",
    "\n",
    "# Combined rule (unsupervised): IF + DBSCAN + amount threshold\n",
    "clusters_test = DBSCAN(eps=0.7, min_samples=8).fit_predict(Xs_test)\n",
    "combined = []\n",
    "for i in range(len(X_test)):\n",
    "    ai = 0\n",
    "    if iso_pred[i] == 1: ai += 1\n",
    "    if clusters_test[i] == -1: ai += 1\n",
    "    if X_test.loc[i, 'amount'] > 5000: ai += 1\n",
    "    combined.append(1 if ai >= 2 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebff700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reveal labels for evaluation (after predictions)\n",
    "test_labels = tx_test[['id']].merge(labels, on='id', how='left')['is_fraudulent'].fillna(0).astype(int).values\n",
    "\n",
    "# Metrics\n",
    "def metric_block(y_true, y_pred, scores=None):\n",
    "    out = {\n",
    "        'accuracy': float(accuracy_score(y_true, y_pred)),\n",
    "        'precision': float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "        'recall': float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "        'f1': float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        'confusion_matrix': confusion_matrix(y_true, y_pred).tolist(),\n",
    "        'classification_report': classification_report(y_true, y_pred, zero_division=0)\n",
    "    }\n",
    "    if scores is not None:\n",
    "        inv = -scores  # invert so higher means more anomalous\n",
    "        out['roc_auc'] = float(roc_auc_score(y_true, inv))\n",
    "        out['average_precision'] = float(average_precision_score(y_true, inv))\n",
    "    return out\n",
    "\n",
    "results = {\n",
    "    'IsolationForest': metric_block(test_labels, iso_pred, iso_score),\n",
    "    'Combined': metric_block(test_labels, np.array(combined))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8f7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot confusion matrix for IsolationForest\n",
    "cm = confusion_matrix(test_labels, iso_pred)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix - IsolationForest')\n",
    "plt.colorbar()\n",
    "tick_marks = [0, 1]\n",
    "plt.xticks(tick_marks, ['Legit', 'Fraud'])\n",
    "plt.yticks(tick_marks, ['Legit', 'Fraud'])\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), horizontalalignment=\"center\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
